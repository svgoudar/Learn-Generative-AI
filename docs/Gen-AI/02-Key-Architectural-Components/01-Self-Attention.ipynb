{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48697b4d",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Attention Mechanism\n",
    "\n",
    "**Attention Mechanism** is the core operation inside Transformers (and therefore LLMs) that allows the model to **focus on the most relevant tokens** in a sequence when generating or understanding text.\n",
    "\n",
    "Below is a clean explanation.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What Attention Does (Intuition)**\n",
    "\n",
    "For every word (token), the model asks:\n",
    "\n",
    "**“Which other words in the sentence should I pay attention to?”**\n",
    "\n",
    "Example:\n",
    "In the sentence *“The cat sat on the mat because it was tired.”*\n",
    "The model must understand that **“it” refers to “cat”**, not “mat”.\n",
    "\n",
    "Attention assigns **scores** to all token pairs to decide relevance.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. How Attention Works (Simple Explanation)**\n",
    "\n",
    "Each token is converted into three vectors:\n",
    "\n",
    "1. **Q (Query)** – What this token is looking for\n",
    "2. **K (Key)** – What this token offers\n",
    "3. **V (Value)** – Actual information content\n",
    "\n",
    "Then attention is computed as:\n",
    "\n",
    "```\n",
    "Attention = softmax( Q · Kᵀ / √d ) · V\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "* `Q · Kᵀ` = similarity between tokens\n",
    "* `√d` = scaling factor\n",
    "* `softmax` = turns scores into probabilities\n",
    "* The result is a **weighted mix of all value vectors**\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Why Self-Attention Is Powerful**\n",
    "\n",
    "Self-attention lets each token look at *all* other tokens simultaneously.\n",
    "This allows the model to learn:\n",
    "\n",
    "* long-range dependencies\n",
    "* context relationships\n",
    "* meaning across distant words\n",
    "* structural patterns\n",
    "\n",
    "Traditional RNNs could not do this efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Multi-Head Attention**\n",
    "\n",
    "Instead of one attention calculation, LLMs use **multiple heads**.\n",
    "\n",
    "Each head learns:\n",
    "\n",
    "* different types of relationships\n",
    "* different semantic patterns\n",
    "\n",
    "Example heads:\n",
    "\n",
    "* “subject → verb” relationships\n",
    "* “coreference” (pronoun resolution)\n",
    "* “syntax patterns”\n",
    "* “entity tracking”\n",
    "* “reasoning links”\n",
    "\n",
    "All heads are concatenated and combined.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Why LLMs Scale So Well with Attention**\n",
    "\n",
    "#### Advantages:\n",
    "\n",
    "* Parallelizable (unlike RNNs)\n",
    "* Global context understanding\n",
    "* Works for very long sequences\n",
    "* Learns complex reasoning patterns\n",
    "\n",
    "#### Disadvantages:\n",
    "\n",
    "* Quadratic compute cost: O(n²) (each token looks at all tokens)\n",
    "\n",
    "This is why modern models use:\n",
    "\n",
    "* Sliding window attention\n",
    "* Sparse attention\n",
    "* FlashAttention\n",
    "* ALiBi, RoPE embeddings\n",
    "* Long-context optimization\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Types of Attention in LLMs**\n",
    "\n",
    "* **Self-attention**: token attends to *other tokens* in same input\n",
    "* **Cross-attention** (in encoder–decoder): decoder attends to encoder output\n",
    "* **Causal attention** (GPT-style): token can only attend to *earlier* tokens\n",
    "\n",
    "Causal attention ensures next-token prediction is valid.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Summary (Easy Version)**\n",
    "\n",
    "* Attention lets LLMs decide *which words matter most*.\n",
    "* It uses **Q, K, V vectors** to compute relevance.\n",
    "* Multi-head attention captures many relationships at once.\n",
    "* It enables long-context understanding and reasoning.\n",
    "\n",
    "\n",
    "Below is a **simple, clear, step-by-step demonstration** of the **attention mechanism**, using a small sentence with tiny numbers so you can see exactly how attention is computed.\n",
    "\n",
    "I will show:\n",
    "\n",
    "1. Token embeddings\n",
    "2. How Q, K, V are computed\n",
    "3. How attention scores are produced\n",
    "4. Softmax\n",
    "5. Weighted sum of values\n",
    "6. Final attention output\n",
    "\n",
    "Everything is numeric, simple, and visible.\n",
    "\n",
    "---\n",
    "\n",
    "### **Sentence**\n",
    "\n",
    "**“The cat sleeps.”**\n",
    "\n",
    "Tokens:\n",
    "\n",
    "1. The\n",
    "2. cat\n",
    "3. sleeps\n",
    "\n",
    "We will compute **attention for the token \"cat\"** (token 2).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1 — Token embeddings (toy 2-dimensional vectors)**\n",
    "\n",
    "These are not real embeddings; just example numeric vectors.\n",
    "\n",
    "```\n",
    "x_the    = [1, 0]\n",
    "x_cat    = [0, 1]\n",
    "x_sleeps = [1, 1]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2 — Define WQ, WK, WV matrices (simple numbers)**\n",
    "\n",
    "These are the *learned weights* in real LLMs, but here we use simple matrices.\n",
    "\n",
    "Assume:\n",
    "\n",
    "```\n",
    "WQ = [[1, 0],\n",
    "      [0, 1]]\n",
    "\n",
    "WK = [[1, 1],\n",
    "      [0, 1]]\n",
    "\n",
    "WV = [[1, 0],\n",
    "      [0, 2]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3 — Compute Q, K, V for each token**\n",
    "\n",
    "Use the formula:\n",
    "\n",
    "$$\n",
    "Q = XW_Q,;; K = XW_K,;; V = XW_V\n",
    "$$\n",
    "\n",
    "#### For **“cat”**:\n",
    "\n",
    "```\n",
    "Q_cat = x_cat @ WQ = [0,1] @ [[1,0],[0,1]] \n",
    "       = [0*1 + 1*0 , 0*0 + 1*1] \n",
    "       = [0, 1]\n",
    "```\n",
    "\n",
    "#### For **keys**:\n",
    "\n",
    "```\n",
    "K_the    = [1,0] @ [[1,1],[0,1]] = [1,1]\n",
    "K_cat    = [0,1] @ [[1,1],[0,1]] = [0,1]\n",
    "K_sleeps = [1,1] @ [[1,1],[0,1]] = [1,2]\n",
    "```\n",
    "\n",
    "#### For **values**:\n",
    "\n",
    "```\n",
    "V_the    = [1,0] @ [[1,0],[0,2]] = [1,0]\n",
    "V_cat    = [0,1] @ [[1,0],[0,2]] = [0,2]\n",
    "V_sleeps = [1,1] @ [[1,0],[0,2]] = [1,2]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4 — Compute attention scores using Q · Kᵀ**\n",
    "\n",
    "$$\n",
    "\\text{score} = Q_{cat} \\cdot K^T\n",
    "$$\n",
    "\n",
    "#### Score(cat → The)\n",
    "\n",
    "```\n",
    "[0,1] · [1,1] = 0*1 + 1*1 = 1\n",
    "```\n",
    "\n",
    "#### Score(cat → cat)\n",
    "\n",
    "```\n",
    "[0,1] · [0,1] = 0*0 + 1*1 = 1\n",
    "```\n",
    "\n",
    "#### Score(cat → sleeps)\n",
    "\n",
    "```\n",
    "[0,1] · [1,2] = 0*1 + 1*2 = 2\n",
    "```\n",
    "\n",
    "#### Raw scores:\n",
    "\n",
    "```\n",
    "[1, 1, 2]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5 — Apply softmax to scores**\n",
    "\n",
    "Softmax converts scores to probabilities (attention weights).\n",
    "\n",
    "Compute exponentials:\n",
    "\n",
    "```\n",
    "exp([1,1,2]) = [2.718, 2.718, 7.389]\n",
    "sum = 12.825\n",
    "```\n",
    "\n",
    "Attention weights:\n",
    "\n",
    "```\n",
    "[2.718/12.825 , 2.718/12.825 , 7.389/12.825]\n",
    "= [0.212 , 0.212 , 0.576]\n",
    "```\n",
    "\n",
    "### Final attention weights:\n",
    "\n",
    "```\n",
    "The    = 0.212\n",
    "cat    = 0.212\n",
    "sleeps = 0.576\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "* “sleeps” is most relevant to “cat”\n",
    "* “The” and “cat” have lower relevance\n",
    "\n",
    "This makes sense: **“cat sleeps”** is a strong phrase.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6 — Weighted sum of Value vectors**\n",
    "\n",
    "Now multiply each V vector with its attention weight.\n",
    "\n",
    "#### From “The”\n",
    "\n",
    "```\n",
    "0.212 * [1,0] = [0.212 , 0]\n",
    "```\n",
    "\n",
    "#### From “cat”\n",
    "\n",
    "```\n",
    "0.212 * [0,2] = [0 , 0.424]\n",
    "```\n",
    "\n",
    "#### From “sleeps”\n",
    "\n",
    "```\n",
    "0.576 * [1,2] = [0.576 , 1.152]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 7 — Add all weighted values**\n",
    "\n",
    "```\n",
    "[0.212 , 0] \n",
    "+ [0 , 0.424]\n",
    "+ [0.576 , 1.152]\n",
    "= [0.788 , 1.576]\n",
    "```\n",
    "\n",
    "#### **Final attention output for “cat”:**\n",
    "\n",
    "```\n",
    "[0.788 , 1.576]\n",
    "```\n",
    "\n",
    "This is the new, context-aware representation of the token “cat”.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Interpretation**\n",
    "\n",
    "The model internally computed:\n",
    "\n",
    "* “cat” relates strongly to “sleeps” → highest attention weight\n",
    "* “cat” relates moderately to “The” and itself\n",
    "* It created a new vector representing “cat in context”\n",
    "\n",
    "This vector goes into the next transformer layer.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "1. Tokens → embeddings\n",
    "2. Multiply by WQ, WK, WV → get Q, K, V\n",
    "3. Compute attention scores (dot product Q·Kᵀ)\n",
    "4. Apply softmax → weights\n",
    "5. Weighted sum of V → attention output\n",
    "\n",
    "This is exactly how attention works in LLMs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
