{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0166f7fb",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Logging \n",
    "\n",
    "### 1. Definition and Purpose\n",
    "\n",
    "**Logging** is the systematic recording of events, data, and decisions occurring inside a Generative AI system during **training**, **inference**, and **deployment**.\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "| Goal          | Description                                     |\n",
    "| ------------- | ----------------------------------------------- |\n",
    "| Observability | Understand what the model and system are doing  |\n",
    "| Debugging     | Detect failures, hallucinations, latency, drift |\n",
    "| Monitoring    | Track health, performance, and cost             |\n",
    "| Auditability  | Ensure compliance and traceability              |\n",
    "| Optimization  | Improve quality, speed, and reliability         |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Where Logging Occurs in a GenAI Pipeline\n",
    "\n",
    "```text\n",
    "User Prompt\n",
    "   ↓\n",
    "Preprocessing → Retrieval → Prompt Assembly → LLM Inference → Postprocessing → Output\n",
    "        ↑              ↑            ↑                ↑              ↑\n",
    "     Log inputs     Log hits    Log prompts     Log tokens      Log scores\n",
    "```\n",
    "\n",
    "**Logging layers**\n",
    "\n",
    "1. **Application layer** — user events, API calls, latency\n",
    "2. **Prompt layer** — prompts, templates, system messages\n",
    "3. **Model layer** — tokens, probabilities, reasoning steps (when available)\n",
    "4. **Data layer** — retrieved documents, embeddings, sources\n",
    "5. **Infrastructure layer** — GPU/CPU usage, memory, failures\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Core Logging Categories\n",
    "\n",
    "| Category         | What is Logged                           |\n",
    "| ---------------- | ---------------------------------------- |\n",
    "| Interaction logs | user prompt, system prompt, model output |\n",
    "| Token logs       | input/output tokens, cost, latency       |\n",
    "| Retrieval logs   | documents retrieved, scores, sources     |\n",
    "| Quality logs     | feedback, ratings, hallucination flags   |\n",
    "| Safety logs      | refusals, moderation events              |\n",
    "| Performance logs | throughput, failures, retries            |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Why Logging is Critical in Generative AI\n",
    "\n",
    "| Problem           | How Logging Helps                     |\n",
    "| ----------------- | ------------------------------------- |\n",
    "| Hallucination     | Compare output with retrieved sources |\n",
    "| Prompt regression | Track which prompt versions degrade   |\n",
    "| Model drift       | Observe output quality over time      |\n",
    "| Latency spikes    | Identify slow components              |\n",
    "| Cost explosion    | Monitor token usage per request       |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Logging Workflow\n",
    "\n",
    "```text\n",
    "Event occurs → Structured log record → Storage → Indexing → Analysis → Alerting\n",
    "```\n",
    "\n",
    "**Typical fields**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"timestamp\": \"2025-12-26T10:00:12Z\",\n",
    "  \"user_id\": \"u42\",\n",
    "  \"model\": \"gpt-4.1\",\n",
    "  \"prompt\": \"...\",\n",
    "  \"response\": \"...\",\n",
    "  \"input_tokens\": 430,\n",
    "  \"output_tokens\": 210,\n",
    "  \"latency_ms\": 980,\n",
    "  \"retrieval_docs\": [\"doc7\", \"doc19\"],\n",
    "  \"hallucination_flag\": false\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Demonstration with Code\n",
    "\n",
    "#### Minimal Python Logging for LLM Calls\n",
    "\n",
    "```python\n",
    "import time, json, logging\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "logging.basicConfig(filename=\"genai.log\", level=logging.INFO)\n",
    "\n",
    "def call_llm(prompt):\n",
    "    start = time.time()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    latency = (time.time() - start) * 1000\n",
    "    usage = response.usage\n",
    "    \n",
    "    record = {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response.choices[0].message.content,\n",
    "        \"input_tokens\": usage.prompt_tokens,\n",
    "        \"output_tokens\": usage.completion_tokens,\n",
    "        \"latency_ms\": round(latency, 2)\n",
    "    }\n",
    "    \n",
    "    logging.info(json.dumps(record))\n",
    "    return record\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Types of Logging in GenAI Systems\n",
    "\n",
    "| Type                 | Description                                           |\n",
    "| -------------------- | ----------------------------------------------------- |\n",
    "| Synchronous logging  | Logs during request handling                          |\n",
    "| Asynchronous logging | Logs streamed to queue or data lake                   |\n",
    "| Structured logging   | JSON-formatted, machine-readable                      |\n",
    "| Trace logging        | End-to-end request tracing                            |\n",
    "| Semantic logging     | Meaning-based signals (e.g., hallucination, toxicity) |\n",
    "| Feedback logging     | Human ratings and corrections                         |\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Logging + Evaluation Loop\n",
    "\n",
    "```text\n",
    "Logs → Dataset → Error Analysis → Prompt Fix → Re-deploy → New Logs\n",
    "```\n",
    "\n",
    "This creates a **continuous improvement cycle** for the GenAI system.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Advanced Logging Practices\n",
    "\n",
    "| Practice                  | Benefit                          |\n",
    "| ------------------------- | -------------------------------- |\n",
    "| Prompt versioning         | Reproduce behaviors              |\n",
    "| Embedding logging         | Diagnose retrieval failures      |\n",
    "| Chain-of-thought masking  | Preserve privacy while debugging |\n",
    "| Redaction & PII filtering | Security & compliance            |\n",
    "| Sampling                  | Control storage costs            |\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Relationship to Other Concepts\n",
    "\n",
    "| Concept             | Connection                         |\n",
    "| ------------------- | ---------------------------------- |\n",
    "| Monitoring          | Built from logs                    |\n",
    "| Evaluation          | Uses logs as dataset               |\n",
    "| Observability       | Logging is foundational            |\n",
    "| Knowledge grounding | Logs show which knowledge was used |\n",
    "| Prompt engineering  | Logs guide prompt optimization     |\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Summary\n",
    "\n",
    "**Logging is the nervous system of Generative AI systems.**\n",
    "Without robust logging, large language models become un-debuggable, unsafe, and unmaintainable.\n",
    "\n",
    "A production-grade GenAI system is impossible without comprehensive logging.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
