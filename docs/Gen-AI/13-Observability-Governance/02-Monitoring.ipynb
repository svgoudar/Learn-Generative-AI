{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd73422c",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Monitoring\n",
    "\n",
    "### 1. Definition & Motivation\n",
    "\n",
    "**Monitoring** in Generative AI is the continuous measurement, analysis, and control of a deployed model’s **behavior, performance, safety, cost, and reliability** in real-world usage.\n",
    "\n",
    "Unlike classical ML, Generative AI systems:\n",
    "\n",
    "* interact directly with users,\n",
    "* produce open-ended outputs,\n",
    "* evolve with data, prompts, and tool integrations,\n",
    "\n",
    "therefore require **real-time, multi-dimensional monitoring**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What Must Be Monitored\n",
    "\n",
    "| Category                  | What is Measured                            | Why It Matters             |\n",
    "| ------------------------- | ------------------------------------------- | -------------------------- |\n",
    "| **Model Quality**         | Accuracy, relevance, hallucination rate     | Prevents degradation       |\n",
    "| **Safety & Alignment**    | Toxicity, bias, harmful content, jailbreaks | Regulatory & ethical risk  |\n",
    "| **Drift**                 | Data drift, concept drift, prompt drift     | Detects model misalignment |\n",
    "| **Latency & Reliability** | Response time, uptime, error rate           | UX and system stability    |\n",
    "| **Cost & Usage**          | Tokens, requests, tool calls                | Budget control             |\n",
    "| **Security**              | Prompt injection, leakage, abuse            | Prevents exploitation      |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Monitoring Architecture\n",
    "\n",
    "```\n",
    "User → Prompt → LLM → Output\n",
    "         ↓         ↓\n",
    "    Prompt Logs   Output Logs\n",
    "         ↓         ↓\n",
    "   Metrics Engine → Alerts → Dashboards\n",
    "         ↓\n",
    "   Drift / Safety / Quality Evaluators\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Core Monitoring Dimensions\n",
    "\n",
    "### 4.1 Quality Monitoring\n",
    "\n",
    "Key metrics:\n",
    "\n",
    "* **Relevance Score**\n",
    "* **Factuality / Hallucination Rate**\n",
    "* **Helpfulness**\n",
    "* **Coherence**\n",
    "\n",
    "**Automated evaluation example**\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def evaluate_response(prompt, response):\n",
    "    judge = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=f\"Score factuality and relevance (0-1).\\nPrompt: {prompt}\\nResponse: {response}\"\n",
    "    )\n",
    "    return judge.output_text\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Safety & Alignment Monitoring\n",
    "\n",
    "Detect:\n",
    "\n",
    "* toxicity\n",
    "* hate / violence\n",
    "* self-harm\n",
    "* policy violations\n",
    "* jailbreak attempts\n",
    "\n",
    "```python\n",
    "safety = client.moderations.create(\n",
    "    model=\"omni-moderation-latest\",\n",
    "    input=response_text\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Drift Monitoring\n",
    "\n",
    "| Drift Type        | What Changes                        |\n",
    "| ----------------- | ----------------------------------- |\n",
    "| **Data Drift**    | User input distribution             |\n",
    "| **Prompt Drift**  | System + user instruction evolution |\n",
    "| **Concept Drift** | Meaning of outputs over time        |\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "drift = wasserstein_distance(old_embeddings, new_embeddings)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 Performance & Reliability\n",
    "\n",
    "Monitor:\n",
    "\n",
    "* p50 / p95 latency\n",
    "* token throughput\n",
    "* API error rate\n",
    "* tool-call success rate\n",
    "\n",
    "```python\n",
    "latency = end_time - start_time\n",
    "error_rate = failed_requests / total_requests\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4.5 Cost & Usage\n",
    "\n",
    "```python\n",
    "cost = tokens_used * cost_per_token\n",
    "```\n",
    "\n",
    "Track:\n",
    "\n",
    "* tokens per user\n",
    "* tokens per feature\n",
    "* cost per workflow\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Alerting & Governance\n",
    "\n",
    "| Condition       | Action                    |\n",
    "| --------------- | ------------------------- |\n",
    "| Hallucination ↑ | Retrain / tighten prompts |\n",
    "| Toxicity spike  | Block + investigate       |\n",
    "| Drift detected  | Refresh data / prompts    |\n",
    "| Latency ↑       | Scale infra               |\n",
    "| Cost ↑          | Enforce quotas            |\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Human-in-the-Loop Monitoring\n",
    "\n",
    "Certain failures require **human validation**:\n",
    "\n",
    "* subjective quality\n",
    "* edge-case safety\n",
    "* regulatory compliance\n",
    "* domain-specific correctness\n",
    "\n",
    "```text\n",
    "Auto metrics → Uncertain cases → Human review → Feedback → Model updates\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Production Workflow Summary\n",
    "\n",
    "1. **Log everything** (prompt, output, metadata)\n",
    "2. **Compute metrics continuously**\n",
    "3. **Detect drift and anomalies**\n",
    "4. **Trigger alerts**\n",
    "5. **Route critical cases to humans**\n",
    "6. **Retrain / reconfigure**\n",
    "7. **Repeat**\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Why Monitoring is Mandatory for GenAI\n",
    "\n",
    "| Without Monitoring  | With Monitoring      |\n",
    "| ------------------- | -------------------- |\n",
    "| Silent failures     | Early detection      |\n",
    "| Safety risks        | Controlled behavior  |\n",
    "| Cost overruns       | Budget governance    |\n",
    "| Trust erosion       | Stable deployment    |\n",
    "| Regulatory exposure | Compliance readiness |\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Conceptual Comparison\n",
    "\n",
    "| Traditional ML       | Generative AI             |\n",
    "| -------------------- | ------------------------- |\n",
    "| Static outputs       | Open-ended outputs        |\n",
    "| Periodic evaluation  | Continuous evaluation     |\n",
    "| Few metrics          | Multi-dimensional metrics |\n",
    "| Offline drift checks | Real-time drift detection |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Insight\n",
    "\n",
    "**Monitoring is not an accessory in Generative AI — it is the control system of intelligence in production.**\n",
    "\n",
    "Without monitoring, Generative AI systems become:\n",
    "\n",
    "* untrustworthy,\n",
    "* unsafe,\n",
    "* expensive,\n",
    "* and uncontrollable.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
