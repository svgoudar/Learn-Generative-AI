{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16e9aa1",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Vector Database\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Motivation and Role in Generative AI\n",
    "\n",
    "Large Language Models (LLMs) do **not store factual knowledge explicitly** in an updatable form.\n",
    "They generate text based on patterns learned during training.\n",
    "\n",
    "**Vector Databases** solve this limitation by enabling:\n",
    "\n",
    "* External, updatable knowledge storage\n",
    "* Semantic search over unstructured data\n",
    "* Efficient retrieval for **Retrieval-Augmented Generation (RAG)** systems\n",
    "\n",
    "> **Core idea:**\n",
    "> Convert information into vectors → store them → retrieve relevant vectors at inference time → inject into LLM context.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What Is a Vector Database?\n",
    "\n",
    "A **Vector Database** stores high-dimensional numerical vectors and supports fast **similarity search**.\n",
    "\n",
    "Each entry:\n",
    "\n",
    "```\n",
    "(id, vector_embedding, metadata, raw_content)\n",
    "```\n",
    "\n",
    "| Component        | Description                         |\n",
    "| ---------------- | ----------------------------------- |\n",
    "| **Embedding**    | Numeric representation of meaning   |\n",
    "| **Metadata**     | Source, timestamp, tags             |\n",
    "| **Index**        | Data structure enabling fast search |\n",
    "| **Query Engine** | Finds nearest neighbors             |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. How Vector Databases Fit into Generative AI\n",
    "\n",
    "### Generative AI Pipeline with Vector DB\n",
    "\n",
    "```\n",
    "User Query\n",
    "   ↓\n",
    "Embedding Model → Query Vector\n",
    "   ↓\n",
    "Vector Database → Top-k Similar Documents\n",
    "   ↓\n",
    "Prompt Construction\n",
    "   ↓\n",
    "LLM → Final Answer\n",
    "```\n",
    "\n",
    "This architecture is known as **Retrieval-Augmented Generation (RAG)**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Why Vectors Work\n",
    "\n",
    "Embeddings map text into a continuous semantic space:\n",
    "\n",
    "| Text                       | Vector                   |\n",
    "| -------------------------- | ------------------------ |\n",
    "| \"AI in healthcare\"         | [0.12, -0.77, 1.02, ...] |\n",
    "| \"medical machine learning\" | [0.11, -0.75, 1.01, ...] |\n",
    "\n",
    "Distance between vectors ≈ **semantic similarity**\n",
    "\n",
    "Common similarity metrics:\n",
    "\n",
    "* Cosine similarity\n",
    "* Euclidean distance\n",
    "* Dot product\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Indexing & Search Internals\n",
    "\n",
    "Vector databases use **Approximate Nearest Neighbor (ANN)** algorithms:\n",
    "\n",
    "| Algorithm | Purpose                 |\n",
    "| --------- | ----------------------- |\n",
    "| HNSW      | Graph-based fast search |\n",
    "| IVF       | Cluster-based search    |\n",
    "| PQ        | Memory compression      |\n",
    "| ScaNN     | Google’s optimized ANN  |\n",
    "\n",
    "Trade-off: **Speed ↔ Accuracy**\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Types of Vector Databases\n",
    "\n",
    "| Type             | Examples                           |\n",
    "| ---------------- | ---------------------------------- |\n",
    "| **Standalone**   | Pinecone, Weaviate, Milvus, Qdrant |\n",
    "| **Hybrid DB**    | PostgreSQL + pgvector              |\n",
    "| **Cloud Native** | Azure AI Search, Amazon OpenSearch |\n",
    "| **In-Memory**    | FAISS                              |\n",
    "\n",
    "---\n",
    "\n",
    "### 7. End-to-End Example (Python)\n",
    "\n",
    "### Step 1 — Generate Embeddings\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "documents = [\"Neural networks\", \"Deep learning in vision\", \"Transformers for NLP\"]\n",
    "vectors = model.encode(documents)\n",
    "```\n",
    "\n",
    "### Step 2 — Store in Vector Database (FAISS)\n",
    "\n",
    "```python\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "index = faiss.IndexFlatL2(vectors.shape[1])\n",
    "index.add(np.array(vectors))\n",
    "```\n",
    "\n",
    "### Step 3 — Query\n",
    "\n",
    "```python\n",
    "query = model.encode([\"How do transformers work?\"])\n",
    "D, I = index.search(np.array(query), k=2)\n",
    "\n",
    "for i in I[0]:\n",
    "    print(documents[i])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Vector DB vs Traditional DB\n",
    "\n",
    "| Feature        | Traditional DB | Vector DB           |\n",
    "| -------------- | -------------- | ------------------- |\n",
    "| Query type     | Exact match    | Semantic similarity |\n",
    "| Data           | Structured     | Unstructured        |\n",
    "| Indexing       | B-tree, Hash   | ANN graphs          |\n",
    "| AI integration | Limited        | Native              |\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Key Applications in Generative AI\n",
    "\n",
    "| Application     | Benefit                  |\n",
    "| --------------- | ------------------------ |\n",
    "| RAG             | Accurate factual answers |\n",
    "| Chatbots        | Contextual memory        |\n",
    "| Search engines  | Semantic retrieval       |\n",
    "| Recommendation  | Similarity matching      |\n",
    "| Code assistants | Codebase understanding   |\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Summary\n",
    "\n",
    "Vector databases are the **memory layer of Generative AI systems**.\n",
    "\n",
    "They provide:\n",
    "\n",
    "* External knowledge\n",
    "* Semantic search\n",
    "* Scalable retrieval\n",
    "* Hallucination reduction\n",
    "* Continuous learning without retraining\n",
    "\n",
    "**LLMs generate.\n",
    "Vector databases remember.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
