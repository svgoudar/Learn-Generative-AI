{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b6bb24",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Data Ingestion\n",
    "\n",
    "---\n",
    "\n",
    "### 1. What is Data Ingestion?\n",
    "\n",
    "**Data Ingestion** is the systematic process of **collecting, cleaning, transforming, validating, and storing data** so that it can be used effectively by **Generative AI models** for training, fine-tuning, retrieval, and inference.\n",
    "\n",
    "In Generative AI pipelines, ingestion connects **raw information** to **model intelligence**.\n",
    "\n",
    "$$\n",
    "\\text{Raw Data} \\rightarrow \\text{Ingested Knowledge} \\rightarrow \\text{Model Learning / Retrieval}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why Data Ingestion is Critical for Generative AI\n",
    "\n",
    "Generative models learn **distributions of data**. Poor ingestion = poor generation.\n",
    "\n",
    "| Aspect    | Impact on Model                           |\n",
    "| --------- | ----------------------------------------- |\n",
    "| Coverage  | Controls what the model knows             |\n",
    "| Quality   | Controls accuracy and hallucination       |\n",
    "| Freshness | Controls relevance                        |\n",
    "| Structure | Controls retrieval & reasoning efficiency |\n",
    "| Bias      | Controls fairness & safety                |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Types of Data Ingestion in Generative AI\n",
    "\n",
    "| Type                 | Description               | Typical Use                  |\n",
    "| -------------------- | ------------------------- | ---------------------------- |\n",
    "| Batch Ingestion      | Large periodic data loads | Pretraining, dataset refresh |\n",
    "| Streaming Ingestion  | Continuous real-time flow | Chat logs, user feedback     |\n",
    "| Offline Ingestion    | Historical datasets       | Pretraining corpora          |\n",
    "| Online Ingestion     | Live sources              | RAG systems, tools           |\n",
    "| Multimodal Ingestion | Text, image, audio, video | Vision-language models       |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Generative AI Ingestion Pipeline (Workflow)\n",
    "\n",
    "```\n",
    "Sources → Extraction → Cleaning → Normalization → Chunking → \n",
    "Embedding → Indexing → Storage → Retrieval → Model\n",
    "```\n",
    "\n",
    "#### Step-by-step\n",
    "\n",
    "1. **Data Sources**\n",
    "\n",
    "   * Documents, websites, databases, APIs, logs, sensors, images, audio\n",
    "\n",
    "2. **Extraction**\n",
    "\n",
    "   * Web scraping, database queries, file loaders, API pulls\n",
    "\n",
    "3. **Cleaning & Validation**\n",
    "\n",
    "   * Remove duplicates, noise, invalid entries\n",
    "   * Language detection, PII filtering\n",
    "\n",
    "4. **Normalization**\n",
    "\n",
    "   * Tokenization, casing, formatting, encoding\n",
    "\n",
    "5. **Chunking**\n",
    "\n",
    "   * Split long documents into manageable semantic units\n",
    "\n",
    "6. **Embedding**\n",
    "\n",
    "   * Convert chunks → dense vectors\n",
    "\n",
    "7. **Indexing & Storage**\n",
    "\n",
    "   * Vector databases (FAISS, Pinecone, Milvus)\n",
    "   * Metadata stores (SQL/NoSQL)\n",
    "\n",
    "8. **Serving to Model**\n",
    "\n",
    "   * Used in training, fine-tuning, or Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Data Ingestion for Training vs RAG\n",
    "\n",
    "| Dimension         | Model Training   | RAG Systems                 |\n",
    "| ----------------- | ---------------- | --------------------------- |\n",
    "| Purpose           | Learn parameters | Retrieve external knowledge |\n",
    "| Update Speed      | Slow, expensive  | Fast, cheap                 |\n",
    "| Data Size         | Massive          | Targeted                    |\n",
    "| Model Change      | Yes              | No                          |\n",
    "| Typical Ingestion | Large batch      | Continuous streaming        |\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Example: Text Ingestion for RAG (Python)\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load\n",
    "docs = TextLoader(\"manual.txt\").load()\n",
    "\n",
    "# 2. Chunk\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 3. Embed\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode([c.page_content for c in chunks])\n",
    "\n",
    "# 4. Index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(np.array(embeddings))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Multimodal Ingestion Example\n",
    "\n",
    "| Modality | Processing              |\n",
    "| -------- | ----------------------- |\n",
    "| Text     | Tokenization, embedding |\n",
    "| Image    | CNN / Vision encoder    |\n",
    "| Audio    | Spectrogram → encoder   |\n",
    "| Video    | Frame sampling + audio  |\n",
    "\n",
    "All are converted into **shared embedding space** for unified reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Challenges in Generative AI Ingestion\n",
    "\n",
    "* Data drift & staleness\n",
    "* Hallucination from noisy ingestion\n",
    "* Scaling pipelines to billions of records\n",
    "* Latency constraints for online ingestion\n",
    "* Governance: privacy, compliance, lineage\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Modern Data Ingestion Stack for GenAI\n",
    "\n",
    "| Layer      | Tools                        |\n",
    "| ---------- | ---------------------------- |\n",
    "| Extraction | Airbyte, Kafka, Scrapy       |\n",
    "| Processing | Spark, Ray, Beam             |\n",
    "| Chunking   | LangChain, LlamaIndex        |\n",
    "| Embedding  | OpenAI, SentenceTransformers |\n",
    "| Indexing   | FAISS, Milvus, Pinecone      |\n",
    "| Serving    | FastAPI, Redis               |\n",
    "| Monitoring | Prometheus, Evidently        |\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Key Insight\n",
    "\n",
    "> **In Generative AI, data ingestion is not ETL.\n",
    "> It is the foundation of intelligence.**\n",
    "\n",
    "A well-designed ingestion pipeline determines **what your model knows, how well it reasons, and whether it can be trusted.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
