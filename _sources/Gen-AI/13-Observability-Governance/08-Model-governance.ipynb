{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c96689",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Model Governance\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Definition\n",
    "\n",
    "**Model Governance** is the set of **policies, processes, controls, and technical mechanisms** used to ensure that **Generative AI models** are:\n",
    "\n",
    "* **Reliable**\n",
    "* **Safe**\n",
    "* **Fair**\n",
    "* **Compliant**\n",
    "* **Explainable**\n",
    "* **Accountable throughout their lifecycle**\n",
    "\n",
    "It spans **data → training → deployment → monitoring → retirement**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why Model Governance Is Critical for Generative AI\n",
    "\n",
    "Generative models introduce unique risks:\n",
    "\n",
    "| Risk                | Example                          |\n",
    "| ------------------- | -------------------------------- |\n",
    "| Hallucinations      | Fabricated legal citations       |\n",
    "| Bias amplification  | Gender or racial stereotypes     |\n",
    "| Data leakage        | Memorizing private training data |\n",
    "| Unsafe content      | Hate speech, malware generation  |\n",
    "| Regulatory exposure | GDPR, AI Act violations          |\n",
    "| Model drift         | Degrading quality over time      |\n",
    "\n",
    "Without governance, these risks scale catastrophically.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Core Objectives of Model Governance\n",
    "\n",
    "| Objective          | Meaning                              |\n",
    "| ------------------ | ------------------------------------ |\n",
    "| **Safety**         | Prevent harmful outputs              |\n",
    "| **Fairness**       | Minimize bias                        |\n",
    "| **Transparency**   | Explain how and why decisions occur  |\n",
    "| **Accountability** | Clear ownership and responsibility   |\n",
    "| **Compliance**     | Meet legal & regulatory requirements |\n",
    "| **Robustness**     | Reliable under distribution shift    |\n",
    "| **Security**       | Protect model & data                 |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Model Governance Lifecycle\n",
    "\n",
    "```\n",
    "Data → Training → Validation → Deployment → Monitoring → Retirement\n",
    "```\n",
    "\n",
    "| Phase      | Governance Controls                 |\n",
    "| ---------- | ----------------------------------- |\n",
    "| Data       | Consent, provenance, PII filtering  |\n",
    "| Training   | Versioning, experiment tracking     |\n",
    "| Validation | Bias testing, red-teaming           |\n",
    "| Deployment | Access control, policy enforcement  |\n",
    "| Monitoring | Drift detection, incident response  |\n",
    "| Retirement | Decommissioning, audit preservation |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Governance Architecture\n",
    "\n",
    "```\n",
    "+--------------------+\n",
    "| Policy Layer      |  → Legal, ethical, compliance rules\n",
    "+--------------------+\n",
    "| Process Layer     |  → Reviews, approvals, documentation\n",
    "+--------------------+\n",
    "| Technical Layer   |  → Tooling, logging, monitoring\n",
    "+--------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Key Governance Components\n",
    "\n",
    "#### 6.1 Data Governance\n",
    "\n",
    "* Data lineage & provenance\n",
    "* PII detection & removal\n",
    "* Consent tracking\n",
    "* Dataset versioning\n",
    "\n",
    "```python\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "results = analyzer.analyze(\"My SSN is 123-45-6789\", language=\"en\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 6.2 Model Documentation (Model Cards)\n",
    "\n",
    "Includes:\n",
    "\n",
    "* Intended use\n",
    "* Training data sources\n",
    "* Known limitations\n",
    "* Ethical risks\n",
    "* Performance benchmarks\n",
    "\n",
    "---\n",
    "\n",
    "#### 6.3 Validation & Risk Assessment\n",
    "\n",
    "| Test             | Purpose                    |\n",
    "| ---------------- | -------------------------- |\n",
    "| Bias tests       | Detect demographic bias    |\n",
    "| Robustness tests | Adversarial stability      |\n",
    "| Safety tests     | Harmful content generation |\n",
    "| Privacy tests    | Memorization & leakage     |\n",
    "\n",
    "---\n",
    "\n",
    "#### 6.4 Human Oversight\n",
    "\n",
    "* Approval checkpoints\n",
    "* High-risk use case review\n",
    "* Incident escalation procedures\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Governance for Generative-Specific Risks\n",
    "\n",
    "| Risk          | Governance Mechanism            |\n",
    "| ------------- | ------------------------------- |\n",
    "| Hallucination | Grounding, retrieval, citations |\n",
    "| Jailbreaks    | Red-teaming, prompt filtering   |\n",
    "| Data leakage  | Differential privacy            |\n",
    "| IP violations | Training data auditing          |\n",
    "| Misuse        | Access controls, usage policies |\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Monitoring & Continuous Governance\n",
    "\n",
    "#### Metrics\n",
    "\n",
    "* Output toxicity score\n",
    "* Hallucination rate\n",
    "* Bias metrics\n",
    "* Drift metrics\n",
    "* User feedback\n",
    "\n",
    "```python\n",
    "def detect_drift(ref_embeddings, live_embeddings, threshold=0.15):\n",
    "    drift = (ref_embeddings.mean(axis=0) - live_embeddings.mean(axis=0)).norm()\n",
    "    return drift > threshold\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Governance Roles & Responsibilities\n",
    "\n",
    "| Role               | Responsibility            |\n",
    "| ------------------ | ------------------------- |\n",
    "| Model Owner        | End-to-end accountability |\n",
    "| ML Engineers       | Technical compliance      |\n",
    "| Legal & Compliance | Regulatory alignment      |\n",
    "| Ethics Board       | Risk review               |\n",
    "| Security Team      | Threat protection         |\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Regulatory Landscape (Examples)\n",
    "\n",
    "| Regulation    | Focus                          |\n",
    "| ------------- | ------------------------------ |\n",
    "| EU AI Act     | Risk classification & controls |\n",
    "| GDPR          | Privacy, data protection       |\n",
    "| ISO/IEC 23894 | AI risk management             |\n",
    "| NIST AI RMF   | Trustworthy AI framework       |\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Governance Maturity Levels\n",
    "\n",
    "| Level     | Description           |\n",
    "| --------- | --------------------- |\n",
    "| Ad hoc    | No formal controls    |\n",
    "| Defined   | Basic documentation   |\n",
    "| Managed   | Continuous monitoring |\n",
    "| Optimized | Automated governance  |\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Practical Governance Workflow\n",
    "\n",
    "```\n",
    "Use Case Proposal\n",
    "      ↓\n",
    "Risk Assessment\n",
    "      ↓\n",
    "Data & Model Review\n",
    "      ↓\n",
    "Approval & Deployment\n",
    "      ↓\n",
    "Continuous Monitoring\n",
    "      ↓\n",
    "Incident Management\n",
    "      ↓\n",
    "Model Retirement\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 13. Summary\n",
    "\n",
    "Model Governance in Generative AI is **not optional infrastructure**—it is the foundation that makes large-scale deployment **safe, legal, and sustainable**.\n",
    "\n",
    "It integrates:\n",
    "\n",
    "* **Technical controls**\n",
    "* **Organizational processes**\n",
    "* **Regulatory compliance**\n",
    "* **Ethical oversight**\n",
    "\n",
    "into a single continuous lifecycle discipline.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
