{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8402450e",
   "metadata": {},
   "source": [
    "## Zero-Shot and Few-Shot Learning\n",
    "\n",
    "**Zero-shot learning** and **few-shot learning** are techniques that allow models—especially large language models (LLMs)—to perform new tasks with **no task-specific training data** or with **very few examples**.\n",
    "\n",
    "They are foundational to the flexibility of modern generative AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Core Intuition**\n",
    "\n",
    "Traditional ML:\n",
    "\n",
    "> Train a model for each task with labeled data.\n",
    "\n",
    "Modern LLMs:\n",
    "\n",
    "> Use a single pretrained model and describe the task in the prompt.\n",
    "\n",
    "The model **infers the task** from the prompt.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Zero-Shot Learning**\n",
    "\n",
    "#### **Definition**\n",
    "\n",
    "The model performs a task **without seeing any examples**, relying only on instructions.\n",
    "\n",
    "#### **Example**\n",
    "\n",
    "```text\n",
    "Classify the sentiment of the following sentence as Positive or Negative:\n",
    "\"I love this product.\"\n",
    "```\n",
    "\n",
    "#### **How It Works**\n",
    "\n",
    "The pretrained model has learned general language and task patterns during pretraining and can map new instructions to learned behavior.\n",
    "\n",
    "#### **When to Use**\n",
    "\n",
    "* Simple, well-defined tasks\n",
    "* When no labeled examples are available\n",
    "* Rapid prototyping\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Few-Shot Learning**\n",
    "\n",
    "#### **Definition**\n",
    "\n",
    "The model is shown **a small number of examples** in the prompt to guide behavior.\n",
    "\n",
    "#### **Example**\n",
    "\n",
    "```text\n",
    "Translate English to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Good morning\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French:\n",
    "```\n",
    "\n",
    "#### **Why It Helps**\n",
    "\n",
    "Examples clarify:\n",
    "\n",
    "* Task format\n",
    "* Output style\n",
    "* Edge cases\n",
    "\n",
    "#### **When to Use**\n",
    "\n",
    "* Complex or ambiguous tasks\n",
    "* Domain-specific outputs\n",
    "* Structured generation\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Comparison**\n",
    "\n",
    "| Aspect              | Zero-Shot    | Few-Shot      |\n",
    "| ------------------- | ------------ | ------------- |\n",
    "| Data required       | None         | 2–10 examples |\n",
    "| Prompt length       | Short        | Longer        |\n",
    "| Reliability         | Moderate     | High          |\n",
    "| Cost                | Low          | Higher        |\n",
    "| Use-case complexity | Simple tasks | Complex tasks |\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Relationship to In-Context Learning**\n",
    "\n",
    "Both are forms of **in-context learning**:\n",
    "the model adapts behavior **within the prompt itself**, without changing model parameters.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Why This Matters**\n",
    "\n",
    "These techniques enable:\n",
    "\n",
    "* Task generalization\n",
    "* Rapid development\n",
    "* Minimal labeled data dependency\n",
    "* One-model-for-many-tasks systems\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Limitations**\n",
    "\n",
    "* Prompt length constraints\n",
    "* Sensitivity to example quality\n",
    "* Not a replacement for fine-tuning in high-stakes systems\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Summary**\n",
    "\n",
    "| Concept        | Description                         |\n",
    "| -------------- | ----------------------------------- |\n",
    "| Zero-shot      | Learn from instructions             |\n",
    "| Few-shot       | Learn from examples                 |\n",
    "| Key capability | In-context adaptation               |\n",
    "| Impact         | Eliminates task-specific retraining |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
