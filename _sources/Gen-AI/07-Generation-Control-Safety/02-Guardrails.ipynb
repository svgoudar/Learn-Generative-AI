{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae42c81e",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Guardrails\n",
    "\n",
    "### 1. Definition\n",
    "\n",
    "**Guardrails** are **control mechanisms** placed around machine-learning systems—especially Large Language Models (LLMs)—to **ensure safe, reliable, compliant, and goal-aligned behavior** during training, deployment, and usage.\n",
    "\n",
    "They enforce:\n",
    "\n",
    "* **Safety**\n",
    "* **Correctness**\n",
    "* **Policy compliance**\n",
    "* **User intent alignment**\n",
    "* **Operational constraints**\n",
    "\n",
    "Formally, guardrails define a constraint system\n",
    "[\n",
    "\\mathcal{G} : (x, y, c) \\rightarrow { \\text{allow}, \\text{modify}, \\text{block} }\n",
    "]\n",
    "where:\n",
    "\n",
    "* (x) = user input\n",
    "* (y) = model output\n",
    "* (c) = contextual rules & policies\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why Guardrails Are Needed\n",
    "\n",
    "| Problem           | Without Guardrails | With Guardrails        |\n",
    "| ----------------- | ------------------ | ---------------------- |\n",
    "| Hallucinations    | High               | Reduced                |\n",
    "| Unsafe content    | Possible           | Prevented              |\n",
    "| Prompt injection  | Vulnerable         | Detected & neutralized |\n",
    "| Policy violations | Frequent           | Enforced               |\n",
    "| Regulatory risk   | High               | Controlled             |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Guardrails Architecture\n",
    "\n",
    "```\n",
    "User Input\n",
    "   │\n",
    "   ▼\n",
    "[Input Guardrails] ──▶ [Model] ──▶ [Output Guardrails]\n",
    "   │                                   │\n",
    "   └───────[Context & Policy Engine]───┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Types of Guardrails\n",
    "\n",
    "#### A. Input Guardrails\n",
    "\n",
    "Validate and sanitize user input.\n",
    "\n",
    "**Functions**\n",
    "\n",
    "* Prompt injection detection\n",
    "* Toxicity filtering\n",
    "* Schema validation\n",
    "* Intent classification\n",
    "\n",
    "**Example**\n",
    "\n",
    "```python\n",
    "def input_guardrail(prompt):\n",
    "    if detect_injection(prompt):\n",
    "        return \"Blocked: Prompt Injection\"\n",
    "    if is_toxic(prompt):\n",
    "        return \"Blocked: Unsafe Content\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### B. Output Guardrails\n",
    "\n",
    "Validate generated responses.\n",
    "\n",
    "**Functions**\n",
    "\n",
    "* Fact-checking\n",
    "* Policy enforcement\n",
    "* PII redaction\n",
    "* Safety filtering\n",
    "\n",
    "```python\n",
    "def output_guardrail(response):\n",
    "    if contains_pii(response):\n",
    "        response = redact_pii(response)\n",
    "    if violates_policy(response):\n",
    "        return \"Blocked: Policy Violation\"\n",
    "    return response\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### C. Behavioral Guardrails\n",
    "\n",
    "Ensure model follows desired behavior.\n",
    "\n",
    "* Role enforcement\n",
    "* Style constraints\n",
    "* Refusal policies\n",
    "* Scope control\n",
    "\n",
    "---\n",
    "\n",
    "#### D. Knowledge Guardrails\n",
    "\n",
    "Prevent hallucination and enforce grounding.\n",
    "\n",
    "* Retrieval-based grounding\n",
    "* Citation enforcement\n",
    "* Confidence thresholds\n",
    "\n",
    "```python\n",
    "if answer.confidence < 0.7:\n",
    "    return \"Insufficient evidence\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### E. System Guardrails\n",
    "\n",
    "Operational constraints.\n",
    "\n",
    "* Rate limiting\n",
    "* Logging & auditing\n",
    "* Cost control\n",
    "* Abuse monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Guardrails vs Alignment\n",
    "\n",
    "| Concept    | Purpose                               |\n",
    "| ---------- | ------------------------------------- |\n",
    "| Alignment  | Make model *want* to behave correctly |\n",
    "| Guardrails | **Force** model to behave correctly   |\n",
    "\n",
    "Guardrails provide **hard constraints**, alignment provides **soft constraints**.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Guardrails Workflow in Practice\n",
    "\n",
    "```\n",
    "1. Receive user query\n",
    "2. Apply Input Guardrails\n",
    "3. Retrieve grounding knowledge\n",
    "4. Generate response\n",
    "5. Apply Output Guardrails\n",
    "6. Log decision & deliver response\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Example: Guardrails in RAG System\n",
    "\n",
    "```python\n",
    "query = input_guardrail(user_query)\n",
    "\n",
    "docs = retriever.retrieve(query)\n",
    "\n",
    "response = llm.generate(query, docs)\n",
    "\n",
    "final_answer = output_guardrail(response)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Guardrail Techniques\n",
    "\n",
    "| Technique          | Purpose                             |\n",
    "| ------------------ | ----------------------------------- |\n",
    "| Rule-based filters | Fast policy enforcement             |\n",
    "| Classifiers        | Detect unsafe or disallowed content |\n",
    "| LLM-as-judge       | Flexible semantic evaluation        |\n",
    "| Schema validation  | Structured output enforcement       |\n",
    "| Confidence scoring | Hallucination control               |\n",
    "| Human-in-the-loop  | High-risk decisions                 |\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Evaluation Metrics\n",
    "\n",
    "* **Violation Rate**\n",
    "* **False Positive Rate**\n",
    "* **User Satisfaction**\n",
    "* **Hallucination Rate**\n",
    "* **Compliance Accuracy**\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Summary\n",
    "\n",
    "Guardrails transform raw LLMs into **production-grade AI systems** by enforcing safety, reliability, compliance, and trust.\n",
    "They operate across **input, output, behavior, knowledge, and system layers**, forming the backbone of modern AI deployment.\n",
    "\n",
    "Without guardrails, LLMs are **powerful but dangerous**.\n",
    "With guardrails, they become **useful, trustworthy, and scalable systems**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
