{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a6079c",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Content Moderation\n",
    "\n",
    "### 1. Definition and Motivation\n",
    "\n",
    "**Content Moderation** is the process of automatically or semi-automatically identifying, filtering, and managing user-generated content that violates platform policies, legal requirements, or ethical standards.\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "| Risk                     | Consequence                       |\n",
    "| ------------------------ | --------------------------------- |\n",
    "| Toxic or abusive content | User harm, platform degradation   |\n",
    "| Misinformation           | Public trust erosion              |\n",
    "| Illegal content          | Legal liability                   |\n",
    "| Unsafe AI outputs        | Model misuse, reputational damage |\n",
    "\n",
    "Modern moderation systems are **machine-learning pipelines** designed to operate at scale with strict accuracy, latency, and fairness constraints.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Moderation Taxonomy (What is moderated)\n",
    "\n",
    "| Category             | Examples                              |\n",
    "| -------------------- | ------------------------------------- |\n",
    "| Hate & Harassment    | Slurs, threats, bullying              |\n",
    "| Violence & Extremism | Terrorist propaganda, violent threats |\n",
    "| Adult & Sexual       | Explicit content, exploitation        |\n",
    "| Self-harm            | Suicide ideation, encouragement       |\n",
    "| Drugs & Weapons      | Trafficking, manufacturing            |\n",
    "| Misinformation       | Medical, political falsehoods         |\n",
    "| Privacy Violations   | Leaks of personal data                |\n",
    "\n",
    "Each category typically contains **subclasses** with different severity levels.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. System Architecture\n",
    "\n",
    "```\n",
    "User Content\n",
    "     ↓\n",
    "Preprocessing (cleaning, language detection)\n",
    "     ↓\n",
    "Feature Extraction / Embedding\n",
    "     ↓\n",
    "Moderation Models (multi-task classifiers)\n",
    "     ↓\n",
    "Policy Engine (thresholds + rules)\n",
    "     ↓\n",
    "Action (allow / warn / block / escalate)\n",
    "```\n",
    "\n",
    "Key properties:\n",
    "\n",
    "* **Low latency**\n",
    "* **High recall for severe harms**\n",
    "* **Human-in-the-loop for edge cases**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Modeling Approaches\n",
    "\n",
    "| Approach      | Description                                         |\n",
    "| ------------- | --------------------------------------------------- |\n",
    "| Rule-based    | Regex, keyword lists                                |\n",
    "| Classical ML  | TF-IDF + logistic regression                        |\n",
    "| Deep Learning | Transformers (BERT, RoBERTa, GPT-style classifiers) |\n",
    "| Hybrid        | Model + rules + heuristics                          |\n",
    "\n",
    "Modern systems use **multi-label transformers** with shared encoders.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Multi-Label Moderation Formulation\n",
    "\n",
    "Given input text `x`, predict vector:\n",
    "\n",
    "```\n",
    "y = [hate, violence, sexual, self_harm, drugs, misinformation, ...]\n",
    "```\n",
    "\n",
    "Each label is independent:\n",
    "\n",
    "```\n",
    "P(y_i = 1 | x) = σ(W_i · h_x)\n",
    "```\n",
    "\n",
    "Loss:\n",
    "\n",
    "```\n",
    "L = Σ BinaryCrossEntropy(y_i, ŷ_i)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Example: Training a Moderation Classifier\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=5, problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "text = \"I will hurt you if you come here again.\"\n",
    "labels = torch.tensor([[1,1,0,0,0]])  # hate, violence, sexual, self_harm, drugs\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Decision & Policy Layer\n",
    "\n",
    "| Score Range | Action       |\n",
    "| ----------- | ------------ |\n",
    "| < 0.3       | Allow        |\n",
    "| 0.3 – 0.6   | Soft warning |\n",
    "| 0.6 – 0.85  | Block        |\n",
    "\n",
    "> 0.85 | Immediate escalation |\n",
    "\n",
    "Thresholds are tuned per category based on **risk tolerance**.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Human-in-the-Loop Workflow\n",
    "\n",
    "```\n",
    "Model Prediction\n",
    "     ↓\n",
    "Uncertain or High-Risk?\n",
    "     ↓ Yes\n",
    "Human Review\n",
    "     ↓\n",
    "Policy Feedback → Dataset Update → Model Retraining\n",
    "```\n",
    "\n",
    "This loop prevents dataset drift and improves rare-class recall.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Evaluation Metrics\n",
    "\n",
    "| Metric      | Why                        |\n",
    "| ----------- | -------------------------- |\n",
    "| Recall      | Must catch harmful content |\n",
    "| Precision   | Minimize false bans        |\n",
    "| ROC-AUC     | Ranking quality            |\n",
    "| Calibration | Reliable probabilities     |\n",
    "| Latency     | Real-time performance      |\n",
    "\n",
    "Severe categories optimize **recall over precision**.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Deployment Challenges\n",
    "\n",
    "* Class imbalance (toxic content is rare)\n",
    "* Adversarial attacks (obfuscation, code-switching)\n",
    "* Cultural & linguistic variation\n",
    "* Policy evolution\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Advanced Topics\n",
    "\n",
    "* **Contrastive safety training**\n",
    "* **Active learning for rare harms**\n",
    "* **Adversarial data augmentation**\n",
    "* **Cross-lingual moderation**\n",
    "* **Context-aware moderation (conversation-level)**\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Summary\n",
    "\n",
    "Content moderation is a **high-stakes multi-task ML system** combining:\n",
    "\n",
    "* Transformer classifiers\n",
    "* Policy engines\n",
    "* Human feedback loops\n",
    "* Continuous evaluation\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
