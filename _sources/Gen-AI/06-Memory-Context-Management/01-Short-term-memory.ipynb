{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34589f24",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Short-Term Memory \n",
    "\n",
    "### 1. Definition\n",
    "\n",
    "**Short-Term Memory (STM)** in Generative AI refers to the **temporary information storage** that a model uses **within a single interaction or context window** to generate coherent, relevant, and context-aware outputs.\n",
    "\n",
    "It is:\n",
    "\n",
    "* **Session-local**\n",
    "* **Non-persistent**\n",
    "* **Token-bounded**\n",
    "* **Stateless across sessions (by default)**\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why Short-Term Memory Exists\n",
    "\n",
    "LLMs do not have continuous consciousness.\n",
    "They compute each output using only:\n",
    "\n",
    "[\n",
    "P(\\text{next token} \\mid \\text{current context})\n",
    "]\n",
    "\n",
    "The **context** acts as the model’s short-term memory.\n",
    "\n",
    "| Challenge              | Role of STM                             |\n",
    "| ---------------------- | --------------------------------------- |\n",
    "| Coherence across turns | Remembers prior user messages           |\n",
    "| Reference resolution   | Links pronouns, variables, names        |\n",
    "| Task continuity        | Maintains goals and constraints         |\n",
    "| Reasoning chains       | Preserves intermediate steps            |\n",
    "| Instruction following  | Keeps system and developer rules active |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Where STM Lives in the Architecture\n",
    "\n",
    "```\n",
    "[ System Prompt ]\n",
    "[ Developer Prompt ]\n",
    "[ Conversation History ]  ← Short-Term Memory\n",
    "[ Current User Message ]\n",
    "--------------------------------------------\n",
    "            Context Window\n",
    "                    ↓\n",
    "             Transformer\n",
    "                    ↓\n",
    "               Output\n",
    "```\n",
    "\n",
    "STM = **all tokens currently inside the context window**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Characteristics of Short-Term Memory\n",
    "\n",
    "| Property            | Description                                  |\n",
    "| ------------------- | -------------------------------------------- |\n",
    "| **Temporary**       | Disappears after session ends                |\n",
    "| **Token-limited**   | Restricted by model’s context length         |\n",
    "| **Implicit**        | Not a separate module; embedded in attention |\n",
    "| **Differentiable**  | Stored as token embeddings                   |\n",
    "| **Attention-based** | Accessed via self-attention                  |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Mechanism: How STM Works\n",
    "\n",
    "In Transformers, STM is implemented via **self-attention**.\n",
    "\n",
    "For each token:\n",
    "\n",
    "[\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d}}\\right)V\n",
    "]\n",
    "\n",
    "* **Q**: current query\n",
    "* **K,V**: all previous tokens in context\n",
    "* Every token can attend to all others → full memory access\n",
    "\n",
    "This enables:\n",
    "\n",
    "* Long-range dependency tracking\n",
    "* Cross-turn reasoning\n",
    "* Instruction persistence\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Types of Short-Term Memory in Practice\n",
    "\n",
    "| Type                      | Example                         |\n",
    "| ------------------------- | ------------------------------- |\n",
    "| **Instruction memory**    | System + developer messages     |\n",
    "| **Conversational memory** | Past user–assistant turns       |\n",
    "| **Task memory**           | Goals, constraints, variables   |\n",
    "| **Working memory**        | Intermediate reasoning steps    |\n",
    "| **Tool memory**           | Tool outputs inside the context |\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Workflow with STM\n",
    "\n",
    "```\n",
    "User Input\n",
    "    ↓\n",
    "Append to Context\n",
    "    ↓\n",
    "Trim if Exceeds Window\n",
    "    ↓\n",
    "Transformer Computes Attention Over All Tokens\n",
    "    ↓\n",
    "Generate Output Using STM\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Demonstration with Code (Conceptual)\n",
    "\n",
    "```python\n",
    "context = []\n",
    "\n",
    "def chat(user_input):\n",
    "    context.append(f\"User: {user_input}\")\n",
    "    \n",
    "    prompt = \"\\n\".join(context[-4000:])  # STM limited by tokens\n",
    "    output = model.generate(prompt)\n",
    "    \n",
    "    context.append(f\"Assistant: {output}\")\n",
    "    return output\n",
    "```\n",
    "\n",
    "STM is the `context` list currently inside the window.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. STM vs Long-Term Memory\n",
    "\n",
    "| Feature     | Short-Term Memory | Long-Term Memory         |\n",
    "| ----------- | ----------------- | ------------------------ |\n",
    "| Persistence | Session only      | Across sessions          |\n",
    "| Storage     | Context tokens    | External DB / embeddings |\n",
    "| Access      | Attention         | Retrieval                |\n",
    "| Capacity    | Limited           | Scalable                 |\n",
    "| Learning    | No update         | Can accumulate knowledge |\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Failure Modes of STM\n",
    "\n",
    "| Issue          | Cause                   |\n",
    "| -------------- | ----------------------- |\n",
    "| Forgetting     | Context window overflow |\n",
    "| Contradictions | Older info dropped      |\n",
    "| Hallucination  | Missing facts in STM    |\n",
    "| Topic drift    | Poor memory salience    |\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Design Patterns Using STM\n",
    "\n",
    "* **Conversation summarization**\n",
    "* **Memory compression**\n",
    "* **Sliding window context**\n",
    "* **Hierarchical memory**\n",
    "* **Prompt caching**\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Intuition Summary\n",
    "\n",
    "Short-term memory in Generative AI is simply:\n",
    "\n",
    "> **Everything the model can currently “see” inside its context window and attend to while generating tokens.**\n",
    "\n",
    "It is not a database, not a state variable, not persistent storage —\n",
    "it is **attention over tokens**.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next topics that naturally follow this:\n",
    "\n",
    "* Memory compression strategies\n",
    "* How retrieval augments STM\n",
    "* Designing hybrid STM + LTM systems\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
