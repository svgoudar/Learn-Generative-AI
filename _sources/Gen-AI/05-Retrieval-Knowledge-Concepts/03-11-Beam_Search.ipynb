{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d6da62",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Beam Search\n",
    "\n",
    "**Beam Search** is a decoding strategy used to find the **best overall output sequence**, not just the best next token.\n",
    "\n",
    "It keeps **multiple candidate sequences** (“beams”) at each generation step instead of just one.\n",
    "\n",
    "If Greedy Search keeps:\n",
    "\n",
    "```\n",
    "1 best sentence prefix\n",
    "```\n",
    "\n",
    "Beam Search keeps:\n",
    "\n",
    "```\n",
    "k best sentence prefixes\n",
    "```\n",
    "\n",
    "where **k = beam size** (typically 3–10).\n",
    "\n",
    "---\n",
    "\n",
    "### Why Beam Search Exists (Problem with Greedy Search)\n",
    "\n",
    "#### Greedy Search chooses the best next token:\n",
    "\n",
    "```\n",
    "best token at step 1\n",
    "best token at step 2\n",
    "best token at step 3\n",
    "...\n",
    "```\n",
    "\n",
    "But this **does not** guarantee the best *full sentence*, because:\n",
    "\n",
    "* The best sequence is not always made of locally-optimal choices.\n",
    "* Early mistakes cannot be corrected.\n",
    "* Results tend to be bland or repetitive.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Greedy: \"The cat is sitting\"\n",
    "Better: \"The cat sat on the mat\"\n",
    "```\n",
    "\n",
    "Beam Search fixes this.\n",
    "\n",
    "---\n",
    "\n",
    "### How Beam Search Works (Step-by-Step)\n",
    "\n",
    "Let’s use a **beam size = 3** for demonstration.\n",
    "\n",
    "#### Step 1 — Start with BOS token\n",
    "\n",
    "Model gives probabilities for next token:\n",
    "\n",
    "```\n",
    "Candidates:\n",
    "A: 0.40\n",
    "B: 0.35\n",
    "C: 0.20\n",
    "D: 0.05\n",
    "```\n",
    "\n",
    "Beam size = 3 → keep top 3:\n",
    "\n",
    "```\n",
    "[\"A\"], [\"B\"], [\"C\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2 — Expand each beam\n",
    "\n",
    "Each sequence generates the next token:\n",
    "\n",
    "```\n",
    "\"A\" → tokens: A1, A2, A3  \n",
    "\"B\" → tokens: B1, B2, B3  \n",
    "\"C\" → tokens: C1, C2, C3\n",
    "```\n",
    "\n",
    "Now you have 3 × 3 = 9 candidate sequences.\n",
    "\n",
    "#### Step 3 — Score all 9 sequences\n",
    "\n",
    "Keep the **top 3 overall** by total log-probability:\n",
    "\n",
    "```\n",
    "[\"A\", \"2\"]       score = -1.2  \n",
    "[\"B\", \"1\"]       score = -1.3  \n",
    "[\"C\", \"3\"]       score = -1.5  \n",
    "```\n",
    "\n",
    "These 3 become the new beams.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4 — Repeat\n",
    "\n",
    "Expand → score → keep → repeat\n",
    "Until:\n",
    "\n",
    "* max length reached, or\n",
    "* an EOS token is chosen\n",
    "\n",
    "Beam Search ensures that the final sequence is one of the highest-probability sequences overall.\n",
    "\n",
    "---\n",
    "\n",
    "### Beam Search Example (Concrete)\n",
    "\n",
    "Suppose the model probabilities are:\n",
    "\n",
    "#### Step 1:\n",
    "\n",
    "```\n",
    "The (0.6)\n",
    "A    (0.3)\n",
    "It   (0.1)\n",
    "```\n",
    "\n",
    "Beam = 2 → keep: `The`, `A`\n",
    "\n",
    "#### Step 2:\n",
    "\n",
    "Expand both:\n",
    "\n",
    "#### After “The”\n",
    "\n",
    "```\n",
    "The cat    (0.6 × 0.5 = 0.30)\n",
    "The dog    (0.6 × 0.3 = 0.18)\n",
    "The man    (0.6 × 0.2 = 0.12)\n",
    "```\n",
    "\n",
    "#### After “A”\n",
    "\n",
    "```\n",
    "A cat      (0.3 × 0.6 = 0.18)\n",
    "A dog      (0.3 × 0.3 = 0.09)\n",
    "A man      (0.3 × 0.1 = 0.03)\n",
    "```\n",
    "\n",
    "Sort all 6:\n",
    "\n",
    "| Sequence | Score |\n",
    "| -------- | ----- |\n",
    "| The cat  | 0.30  |\n",
    "| A cat    | 0.18  |\n",
    "| The dog  | 0.18  |\n",
    "| The man  | 0.12  |\n",
    "| A dog    | 0.09  |\n",
    "| A man    | 0.03  |\n",
    "\n",
    "Beam = 2 → keep the top 2:\n",
    "\n",
    "**Beams now:**\n",
    "\n",
    "```\n",
    "The cat\n",
    "The dog\n",
    "```\n",
    "\n",
    "Beam search continues like this.\n",
    "\n",
    "---\n",
    "\n",
    "### Strengths of Beam Search\n",
    "\n",
    "#### ✔ Better global sequences\n",
    "\n",
    "Finds sentences with **higher total probability**.\n",
    "\n",
    "#### ✔ More structured output\n",
    "\n",
    "Great for:\n",
    "\n",
    "* translation\n",
    "* summarization\n",
    "* speech recognition\n",
    "\n",
    "#### ✔ Less randomness\n",
    "\n",
    "More deterministic than sampling.\n",
    "\n",
    "---\n",
    "\n",
    "###  Weaknesses of Beam Search\n",
    "\n",
    "#### ✘ Bland outputs\n",
    "\n",
    "Always picks statistically \"safe\" continuations.\n",
    "\n",
    "#### ✘ Repetitive\n",
    "\n",
    "LLMs may output loops or repeated phrases.\n",
    "\n",
    "#### ✘ Slow\n",
    "\n",
    "Computational cost = beam size × sequence length.\n",
    "\n",
    "#### ✘ Not used in modern LLM chat\n",
    "\n",
    "Sampling strategies (top-p + temperature) produce more natural text.\n",
    "\n",
    "---\n",
    "\n",
    "###  When Beam Search Is Used vs. Not Used\n",
    "\n",
    "#### Used in:\n",
    "\n",
    "* Machine translation (traditional)\n",
    "* ASR (speech recognition)\n",
    "* Guarantees best score on probabilistic models\n",
    "* Summarization with fixed-length targets\n",
    "\n",
    "#### **Not used in**:\n",
    "\n",
    "* ChatGPT-like conversational models\n",
    "* Creative writing\n",
    "* Reasoning\n",
    "* Open-ended output\n",
    "\n",
    "Because it produces:\n",
    "\n",
    "* safe\n",
    "* flat\n",
    "* repetitive\n",
    "  responses\n",
    "\n",
    "---\n",
    "\n",
    "**One-Sentence Summary**\n",
    "\n",
    "**Beam Search keeps multiple candidate sequences during generation and chooses the globally best one, producing stable but less creative text.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
