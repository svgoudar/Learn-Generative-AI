{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3e6fe1",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## ETL\n",
    "\n",
    "### 1. What is ETL?\n",
    "\n",
    "**ETL = Extract → Transform → Load**\n",
    "\n",
    "In Generative AI, ETL is the **data engineering backbone** that prepares raw information into high-quality knowledge usable by large language models (LLMs), vector databases, and downstream AI pipelines.\n",
    "\n",
    "> **Goal:** Convert noisy, heterogeneous data into structured, model-ready representations that improve training, retrieval, and inference.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why ETL Is Critical for Generative AI\n",
    "\n",
    "| Challenge         | Role of ETL                                               |\n",
    "| ----------------- | --------------------------------------------------------- |\n",
    "| Unstructured data | Converts PDFs, HTML, logs, images, audio into usable text |\n",
    "| Hallucination     | Improves grounding by feeding verified, clean data        |\n",
    "| Scalability       | Enables continuous ingestion and refresh                  |\n",
    "| Retrieval quality | Creates embeddings, chunks, and metadata                  |\n",
    "| Compliance        | Removes PII, enforces governance                          |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ETL Architecture for GenAI\n",
    "\n",
    "```\n",
    "Data Sources\n",
    "   ↓\n",
    "[ Extract ]\n",
    "   ↓\n",
    "[ Transform ]\n",
    "   ↓\n",
    "[ Load ]\n",
    "   ↓\n",
    "Vector DB / Training Store / Feature Store\n",
    "   ↓\n",
    "LLM Training or RAG Inference\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Extract Stage\n",
    "\n",
    "**Sources:**\n",
    "\n",
    "* PDFs, Word docs, HTML pages\n",
    "* Databases (SQL/NoSQL)\n",
    "* APIs, logs, chat transcripts\n",
    "* Audio/video → speech-to-text\n",
    "* Image → OCR\n",
    "\n",
    "**Operations:**\n",
    "\n",
    "* Parsing & decoding\n",
    "* Language detection\n",
    "* Versioning & provenance tracking\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "docs = PyPDFLoader(\"policy.pdf\").load()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Transform Stage (Core Intelligence Layer)\n",
    "\n",
    "**Key Transformations:**\n",
    "\n",
    "| Category    | Operations                                     |\n",
    "| ----------- | ---------------------------------------------- |\n",
    "| Cleaning    | deduplication, normalization, spell correction |\n",
    "| Structuring | headings, sections, tables extraction          |\n",
    "| Chunking    | token-bounded segmentation                     |\n",
    "| Enrichment  | metadata, tags, timestamps                     |\n",
    "| Filtering   | toxicity, PII removal                          |\n",
    "| Embedding   | convert text → vectors                         |\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "client = OpenAI()\n",
    "vectors = [client.embeddings.create(model=\"text-embedding-3-small\", input=c.page_content).data[0].embedding for c in chunks]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Load Stage\n",
    "\n",
    "**Targets:**\n",
    "\n",
    "* **Vector databases:** FAISS, Pinecone, Weaviate, Milvus\n",
    "* **Training stores:** Parquet, TFRecords\n",
    "* **Knowledge bases / Feature stores**\n",
    "\n",
    "```python\n",
    "import faiss, numpy as np\n",
    "\n",
    "index = faiss.IndexFlatL2(len(vectors[0]))\n",
    "index.add(np.array(vectors).astype(\"float32\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. ETL in Training vs RAG\n",
    "\n",
    "| Use Case     | ETL Objective                  |\n",
    "| ------------ | ------------------------------ |\n",
    "| LLM Training | Large-scale corpus preparation |\n",
    "| Fine-tuning  | Domain-specific data curation  |\n",
    "| RAG systems  | Real-time knowledge ingestion  |\n",
    "| Agents       | Dynamic memory update          |\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Continuous ETL for Production AI\n",
    "\n",
    "```\n",
    "New Data → Streaming ETL → Re-embed → Update Index → Model Inference\n",
    "```\n",
    "\n",
    "**Tools:** Airflow, Prefect, Dagster, Kafka, Spark, Ray\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Common ETL Pitfalls in GenAI\n",
    "\n",
    "| Problem                     | Solution                         |\n",
    "| --------------------------- | -------------------------------- |\n",
    "| Garbage in → hallucinations | Aggressive cleaning & validation |\n",
    "| Poor chunking               | Token-aware splitting            |\n",
    "| Embedding drift             | Re-embed after model upgrades    |\n",
    "| Stale knowledge             | Scheduled refresh pipelines      |\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Conceptual Summary\n",
    "\n",
    "> **ETL is not preprocessing — it is the knowledge engineering layer of Generative AI.**\n",
    "\n",
    "It determines:\n",
    "\n",
    "* what the model knows,\n",
    "* how reliably it retrieves,\n",
    "* and how safely it reasons.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
