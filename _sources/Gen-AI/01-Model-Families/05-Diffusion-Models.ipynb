{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a86ccb4",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Diffusion Models\n",
    "\n",
    "\n",
    "Diffusion Models are **generative models** that learn to **generate new data (like images or audio)** by *reversing a gradual noising process*.\n",
    "\n",
    "Think of it like this:\n",
    "\n",
    "> You take a clean image → slowly add random noise → it becomes pure static.\n",
    ">\n",
    "> Now, a diffusion model learns how to **reverse this process** — starting from pure noise, it learns how to **denoise** step by step until a realistic image reappears.\n",
    "\n",
    "That’s the essence of diffusion.\n",
    "\n",
    "---\n",
    "\n",
    "### High-Level Idea\n",
    "\n",
    "A diffusion model has two processes:\n",
    "\n",
    "#### (a) **Forward Process (Diffusion)**\n",
    "\n",
    "Gradually destroys data by adding Gaussian noise over many small steps.\n",
    "\n",
    "$$\n",
    "x_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t},\\epsilon\n",
    "$$\n",
    "where\n",
    "\n",
    "* $x_0$: original data (e.g., image)\n",
    "* $x_t$: noisy version at timestep $t$\n",
    "* $\\epsilon \\sim \\mathcal{N}(0, I)$: Gaussian noise\n",
    "* $\\alpha_t$: controls how much noise is added at step $t$\n",
    "\n",
    "After many steps, $x_T$ ≈ pure noise.\n",
    "\n",
    "---\n",
    "\n",
    "#### (b) **Reverse Process (Denoising)**\n",
    "\n",
    "The model learns to **reverse** the forward process:\n",
    "$$\n",
    "p_\\theta(x_{t-1} | x_t)\n",
    "$$\n",
    "That is, given a noisy image $x_t$, predict a slightly *cleaner* version $x_{t-1}$.\n",
    "\n",
    "This is done step by step — from noise → structure → realistic image.\n",
    "\n",
    "---\n",
    "\n",
    "### Training Objective\n",
    "\n",
    "The model is trained to predict the **noise** that was added at each step.\n",
    "\n",
    "$$\n",
    "L = \\mathbb{E}*{x_0, \\epsilon, t}\\left[|\\epsilon - \\epsilon*\\theta(x_t, t)|^2\\right]\n",
    "$$\n",
    "\n",
    "* $\\epsilon_\\theta(x_t, t)$: model’s predicted noise\n",
    "* $\\epsilon$: true noise added\n",
    "* The model learns to accurately “remove” noise from any level of corruption.\n",
    "\n",
    "---\n",
    "\n",
    "### Generation Workflow\n",
    "\n",
    "Once trained, the generation process works **backward**:\n",
    "\n",
    "1. Start with **pure noise** $x_T \\sim \\mathcal{N}(0, I)$.\n",
    "2. Use the trained model to predict and subtract noise step by step:\n",
    "   $$\n",
    "   x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - (1-\\alpha_t)\\epsilon_\\theta(x_t, t)) + \\text{small noise}\n",
    "   $$\n",
    "3. After repeating this for all $T$ steps, you get $x_0$ — a realistic image or data sample.\n",
    "\n",
    "This process is **iterative denoising** — like watching a noisy static image slowly clear into a picture.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuitive Analogy\n",
    "\n",
    "| **Process**         | **Analogy**                                                               |\n",
    "| ------------------- | ------------------------------------------------------------------------- |\n",
    "| Forward (Diffusion) | Adding sand grain by grain until the image becomes pure sand.             |\n",
    "| Reverse (Denoising) | Carefully brushing away grains to reveal the hidden sculpture underneath. |\n",
    "\n",
    "---\n",
    "\n",
    "### Why It Works So Well\n",
    "\n",
    "* Diffusion models **don’t rely on adversarial training** (unlike GANs), so they’re **more stable**.\n",
    "* They can model **complex multimodal distributions** — generating very diverse and realistic samples.\n",
    "* Trained on **massive datasets**, they learn rich representations of real-world textures, lighting, and structure.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Equations Summary\n",
    "\n",
    "| **Stage**     | **Equation**                                     | **Purpose**                                                              |                        |\n",
    "| ------------- | ------------------------------------------------ | ------------------------------------------------------------------------ | ---------------------- |\n",
    "| Forward       | $q(x_t                                          | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{\\alpha_t}x_{t-1}, (1-\\alpha_t)I)$     | Add noise gradually    |\n",
    "| Reverse       | $p_\\theta(x_{t-1}                               | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t))$ | Remove noise gradually |\n",
    "| Training Loss | $L = | \\epsilon - \\epsilon_\\theta(x_t, t) |^2$ | Learn to predict noise                                                   |                        |\n",
    "\n",
    "---\n",
    "\n",
    "### Types of Diffusion Models\n",
    "\n",
    "| **Model Type**                                     | **Description**                                           | **Examples**         |\n",
    "| -------------------------------------------------- | --------------------------------------------------------- | -------------------- |\n",
    "| **DDPM** (Denoising Diffusion Probabilistic Model) | Basic diffusion framework using Gaussian noise            | Ho et al., 2020      |\n",
    "| **DDIM** (Deterministic Diffusion Implicit Model)  | Faster generation with fewer steps                        | Improved DDPM        |\n",
    "| **Score-based Models**                             | Use score matching instead of noise prediction            | Song & Ermon, 2020   |\n",
    "| **Latent Diffusion Models (LDM)**                  | Diffusion operates in compressed latent space (efficient) | **Stable Diffusion** |\n",
    "\n",
    "---\n",
    "\n",
    "### Applications\n",
    "\n",
    "| **Domain**                     | **Examples**                                         |\n",
    "| ------------------------------ | ---------------------------------------------------- |\n",
    "| **Text-to-Image Generation**   | Stable Diffusion, DALL·E 2, Imagen                   |\n",
    "| **Super-Resolution**           | Enhancing low-res images                             |\n",
    "| **Image Inpainting**           | Filling missing parts of an image                    |\n",
    "| **Image-to-Image Translation** | Turning sketches → photos, day → night               |\n",
    "| **Video and Audio Generation** | Motion synthesis, speech synthesis                   |\n",
    "| **Medical Imaging**            | Generating realistic MRI scans for data augmentation |\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison: GAN vs Diffusion\n",
    "\n",
    "| **Aspect**       | **GAN**                            | **Diffusion Model**                    |\n",
    "| ---------------- | ---------------------------------- | -------------------------------------- |\n",
    "| Training         | Adversarial (unstable)             | Noise-prediction (stable)              |\n",
    "| Diversity        | Prone to mode collapse             | High diversity                         |\n",
    "| Control          | Difficult to condition             | Easily conditioned (text, class, etc.) |\n",
    "| Generation Speed | Fast                               | Slower (iterative denoising)           |\n",
    "| Output Quality   | Sharp but sometimes artifact-prone | Highly realistic and smooth            |\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Examples\n",
    "\n",
    "* **Stable Diffusion (2022):**\n",
    "  Text-to-image generation using diffusion in a *latent space* (compact representation of images).\n",
    "  Prompts like:\n",
    "\n",
    "  > “A futuristic city skyline at sunset in cyberpunk style”\n",
    "  > generate photorealistic or stylized images.\n",
    "\n",
    "* **DALL·E 3 (OpenAI):**\n",
    "  Combines **transformers + diffusion** for fine-grained text-conditioned image generation.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| **Component**         | **Role**                                        |\n",
    "| --------------------- | ----------------------------------------------- |\n",
    "| **Forward Diffusion** | Gradually adds Gaussian noise to destroy data   |\n",
    "| **Reverse Diffusion** | Neural net learns to denoise step-by-step       |\n",
    "| **Training Goal**     | Learn the probability distribution of real data |\n",
    "| **Output**            | Realistic new samples generated from noise      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442a62c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
