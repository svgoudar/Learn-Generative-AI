{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f81ad5",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Decoder-Only Models (Autoregressive Architecture)\n",
    "\n",
    "A **Decoder-only model** is a neural network architecture that generates text **one token at a time**, using only previously generated tokens as context.\n",
    "This is the architecture behind modern chat models such as **GPT**, **Claude**, **LLaMA**, **Mistral**, and **Gemini**.\n",
    "\n",
    "---\n",
    "\n",
    "### High-Level Idea\n",
    "\n",
    "**Previous tokens → Decoder → Next token → Append → Repeat**\n",
    "\n",
    "The model predicts the **next token** given all previous tokens.\n",
    "\n",
    "---\n",
    "\n",
    "### Core Structure\n",
    "\n",
    "A decoder-only model consists of stacked **Transformer decoder blocks**.\n",
    "\n",
    "Each block contains:\n",
    "\n",
    "1. **Masked self-attention**\n",
    "   Prevents the model from seeing future tokens.\n",
    "2. **Feedforward network**\n",
    "3. **Layer normalization**\n",
    "4. **Residual connections**\n",
    "\n",
    "No encoder. No cross-attention.\n",
    "\n",
    "---\n",
    "\n",
    "### Autoregressive Generation\n",
    "\n",
    "At each step:\n",
    "\n",
    "1. The model reads the full context so far\n",
    "2. Computes probability distribution for the next token\n",
    "3. Samples the next token\n",
    "4. Appends it to the context\n",
    "5. Repeats until completion\n",
    "\n",
    "---\n",
    "\n",
    "### Why Decoder-Only Models Dominate GenAI\n",
    "\n",
    "| Advantage             | Explanation                               |\n",
    "| --------------------- | ----------------------------------------- |\n",
    "| General-purpose       | Can do almost any language task           |\n",
    "| Simple interface      | Single sequence input                     |\n",
    "| Scales extremely well | Parallelizable training                   |\n",
    "| Flexible prompting    | Instructions, memory, tools in one stream |\n",
    "| Powerful reasoning    | Emergent abilities with scale             |\n",
    "\n",
    "---\n",
    "\n",
    "### Training Process\n",
    "\n",
    "* Pretrained with next-token prediction\n",
    "* Instruction-tuned\n",
    "* Aligned using RLHF or similar methods\n",
    "\n",
    "---\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "| Feature            | Decoder-Only                 |\n",
    "| ------------------ | ---------------------------- |\n",
    "| Architecture       | Single stack                 |\n",
    "| Context handling   | Entire history in one stream |\n",
    "| Task specification | Via prompt                   |\n",
    "| Few-shot learning  | Native                       |\n",
    "| Cross-attention    | None                         |\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations\n",
    "\n",
    "* Inefficient for very long inputs\n",
    "* No explicit separation of input and output\n",
    "* Context window is finite\n",
    "* Cost grows with context size\n",
    "\n",
    "---\n",
    "\n",
    "### Examples\n",
    "\n",
    "* GPT-3 / GPT-4 / GPT-4o\n",
    "* Claude\n",
    "* LLaMA\n",
    "* Mistral\n",
    "* Falcon\n",
    "* Gemma\n",
    "\n",
    "---\n",
    "\n",
    "### Encoder–Decoder vs Decoder-Only\n",
    "\n",
    "| Aspect              | Encoder–Decoder | Decoder-Only |\n",
    "| ------------------- | --------------- | ------------ |\n",
    "| Task specialization | High            | Universal    |\n",
    "| Prompt simplicity   | Moderate        | Very high    |\n",
    "| Multi-task learning | Limited         | Excellent    |\n",
    "| System complexity   | Higher          | Lower        |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
